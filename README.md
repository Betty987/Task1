
# ğŸ Snake Game
This repository contains a Python implementation of the classic Snake Game, where the snake is trained using Reinforcement Learning with the Deep Q-Learning algorithm. The project showcases how artificial intelligence can learn to navigate and optimize its gameplay using neural networks and a reward-based learning framework.

# ğŸ§  Algorithm
Deep Q-Learning (DQL) is a reinforcement learning algorithm that combines Q-Learning with deep neural networks. The agent learns to predict the Q-value of state-action pairs using experience replay and target networks.The AI agent uses Deep Q-Learning to make decisions. Through training, the agent learns from its past actions using a neural network that approximates the optimal Q-values for the game state-action pairs.

# ğŸ“‚ File Structure:
```
|â”€â”€ GIF/ # plots and gifs
|
â”œâ”€â”€ agent/
â”‚ â”œâ”€â”€ base_agent.py # The base agent class
â”‚ â”œâ”€â”€ mlp_agent.py # The agent using MLP and DQN
â”‚ â”œâ”€â”€ cnn_agent.py # The agent using CNN and DQN
â”‚ â”œâ”€â”€ greedy_agent.py # A simple agent that runs directly towards food
â”‚ â””â”€â”€ play_game_with_agent.py # Reward func, play func, play and learn func
â”‚
â”œâ”€â”€ common/
â”‚ â”œâ”€â”€ settings.py # Hyperparameters, game size, and game speed
â”‚ â””â”€â”€ utils.py # Helper functions
â”‚
â”œâ”€â”€ game/
â”‚ â”œâ”€â”€ game_display.py # Game display
â”‚ â”œâ”€â”€ game_logic.py # Game logic
â”‚ â”œâ”€â”€ main_game.py # Integrates game_display and game_logic
â”‚ â””â”€â”€ states.py # Game state
â”‚
â”œâ”€â”€ model/
â”‚ â”œâ”€â”€ weights/
â”‚ â”‚ â””â”€â”€ mlp_model.pth # Model weights
â”‚ â”‚ â””â”€â”€ cnn_model.pth # Model weights
â”‚ â””â”€â”€ dqn_model.py # Neural networks
â”‚
|â”€â”€ main.py # Main program, primarily contains user interaction
```
# ğŸ‘¾ Game Structure:
   ``` 
    Start
    â”‚
    â””â”€â”€â”€ Choose agent type
        â”‚
        â”œâ”€â”€â”€ (a) MLP Agent
        â”‚
        â””â”€â”€â”€ (b) CNN Agent
            â”‚
            â””â”€â”€â”€ Choose mode
                â”‚
                â”œâ”€â”€â”€ (a) Play
                â”‚   â”‚
                â”‚   â””â”€â”€â”€ Load previous model
                â”‚       â”‚
                â”‚       â”œâ”€â”€â”€ Success
                â”‚       â”‚   â””â”€â”€â”€ Play with loaded model
                â”‚       â”‚
                â”‚       â””â”€â”€â”€ Fail
                â”‚           â”‚
                â”‚           â””â”€â”€â”€ Continue without loaded model?
                â”‚               â”‚
                â”‚               â”œâ”€â”€â”€ (a) Return to mode selection
                â”‚               â”‚
                â”‚               â””â”€â”€â”€ (b) Play with untrained model
                â”‚
                â””â”€â”€â”€ (b) Learn and Play
                    â”‚
                    â””â”€â”€â”€ Start training from scratch?
                        â”‚
                        â”œâ”€â”€â”€ (a) Load previous model
                        â”‚   â”‚
                        â”‚   â”œâ”€â”€â”€ Success
                        â”‚   â”‚   â””â”€â”€â”€ Play and learn with loaded model
                        â”‚   â”‚
                        â”‚   â””â”€â”€â”€ Fail
                        â”‚       â”‚
                        â”‚       â””â”€â”€â”€ Continue without loaded model?
                        â”‚           â”‚
                        â”‚           â”œâ”€â”€â”€ (a) Return to mode selection 
                        â”‚           â”‚
                        â”‚           â””â”€â”€â”€ (b) Training from scratch
                        â”‚
                        â””â”€â”€â”€ (b) Start new training
    ```
# ğŸ“¹ Demo

![alt text](GIF/loss.png)
![alt text](GIF/snake.gif)
